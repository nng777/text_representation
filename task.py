"""
Part 2: Word Embeddings Exploration
Task 2.1: Word Relationships Analysis
Using either the lesson app or your own implementation:
1.Train a Word2Vec model on a corpus of at least 50 sentences (you can use news articles, book excerpts, or any text source)
2.Find analogies similar to "king - man + woman = queen" using your trained model
3.Analyze semantic clusters by finding words similar to: "happy", "computer", "fast"

Requirements:
1.Use different hyperparameters (vector_size, window, min_count) and compare results
2.Try at least 3 different analogies
3.Document which hyperparameters work best and why

Deliverable:
1.Training code and results
2.Analysis of how hyperparameters affect the quality of word relationships
3.Screenshots or text output of your analogy experiments

Task 2.2: Pre-trained vs Custom Models
Compare the performance of your custom-trained Word2Vec model with a pre-trained model:
1.Load a pre-trained model (Google News vectors or any other available model)
2.Test the same analogies from Task 2.1 on both models
3.Analyze the differences in results and explain why they occur

Deliverable:
1.Comparison table showing results from both models
2.Written explanation (3-4 sentences) of why pre-trained models might perform differently
"""